name: CI

on:
  push:
    branches: [main, master]
  pull_request:
    branches: [main, master]

env:
  CARGO_TERM_COLOR: always
  RUSTFLAGS: "-D warnings"

# Cancel previous runs on the same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

jobs:
  # Fast checks - run first, fail fast
  version-check:
    name: Version Sync
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - uses: actions/checkout@v4
      - name: Check version synchronization
        run: ./scripts/sync-version.sh --check

  format:
    name: Format
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
        with:
          components: rustfmt
      - run: cargo fmt --all -- --check
      - run: cargo fmt --manifest-path compiler/ori_llvm/Cargo.toml -- --check

  clippy:
    name: Clippy
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
        with:
          components: clippy
      - uses: Swatinem/rust-cache@v2
        with:
          key: clippy
      - run: cargo clippy --workspace --all-targets -- -D warnings

  # Main test suite
  test:
    name: Test
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - uses: Swatinem/rust-cache@v2
        with:
          key: test

      - name: Build
        run: cargo build --workspace

      - name: Rust unit tests
        id: rust-tests
        continue-on-error: true
        run: |
          cargo test --workspace 2>&1 | tee rust-test-output.txt
          # Extract test count from output like "test result: ok. 2136 passed; 0 failed"
          RUST_TESTS=$(grep -oP '\d+(?= passed)' rust-test-output.txt | tail -1 || echo "0")
          RUST_FAILED=$(grep -oP '\d+(?= failed)' rust-test-output.txt | tail -1 || echo "0")
          echo "RUST_TESTS=$RUST_TESTS" >> $GITHUB_ENV
          echo "RUST_FAILED=$RUST_FAILED" >> $GITHUB_ENV

      - name: Ori language tests
        id: ori-tests
        continue-on-error: true
        run: |
          cargo run -p oric --bin ori -- test tests/ 2>&1 | tee ori-test-output.txt
          # Extract test count from Ori test output
          ORI_TESTS=$(grep -oP '\d+(?= tests? passed)' ori-test-output.txt | tail -1 || echo "0")
          ORI_FAILED=$(grep -oP '\d+(?= tests? failed)' ori-test-output.txt | tail -1 || echo "0")
          echo "ORI_TESTS=$ORI_TESTS" >> $GITHUB_ENV
          echo "ORI_FAILED=$ORI_FAILED" >> $GITHUB_ENV

      - name: Save test results
        if: always()
        run: |
          cat > test-results.json << EOF
          {
            "rust_tests": ${RUST_TESTS:-0},
            "rust_failed": ${RUST_FAILED:-0},
            "ori_tests": ${ORI_TESTS:-0},
            "ori_failed": ${ORI_FAILED:-0},
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
          }
          EOF
          cat test-results.json

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: test-results.json
          retention-days: 90

      - name: Fail if tests failed
        if: steps.rust-tests.outcome == 'failure' || steps.ori-tests.outcome == 'failure'
        run: exit 1

  # Cross-platform smoke test - just verify it compiles and basic tests pass
  cross-platform:
    name: ${{ matrix.os }}
    needs: [format, clippy]  # Don't waste CI time if basics fail
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20
    strategy:
      fail-fast: false
      matrix:
        os: [macos-latest, windows-latest]
    steps:
      - uses: actions/checkout@v4
      - uses: dtolnay/rust-toolchain@stable
      - uses: Swatinem/rust-cache@v2
        with:
          key: ${{ matrix.os }}

      - name: Build
        run: cargo build --workspace

      - name: Rust unit tests
        run: cargo test --workspace

      - name: Ori language tests
        run: cargo run -p oric --bin ori -- test tests/

  # LLVM backend - runs in Docker, non-blocking for now
  # TODO: Make this blocking once LLVM backend is stable
  llvm:
    name: LLVM Backend
    runs-on: ubuntu-latest
    timeout-minutes: 60
    continue-on-error: true  # Non-blocking during pre-alpha
    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build LLVM Docker image
        uses: docker/build-push-action@v6
        with:
          context: docker/llvm
          load: true
          tags: ori-llvm:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: LLVM clippy
        run: ./llvm-clippy

      - name: LLVM tests
        id: llvm-tests
        continue-on-error: true
        run: |
          ./llvm-test 2>&1 | tee llvm-test-output.txt
          LLVM_TESTS=$(grep -oP '\d+(?= passed)' llvm-test-output.txt | tail -1 || echo "0")
          LLVM_FAILED=$(grep -oP '\d+(?= failed)' llvm-test-output.txt | tail -1 || echo "0")
          echo "LLVM_TESTS=$LLVM_TESTS" >> $GITHUB_ENV
          echo "LLVM_FAILED=$LLVM_FAILED" >> $GITHUB_ENV

      - name: Save LLVM test results
        if: always()
        run: |
          cat > llvm-test-results.json << EOF
          {
            "llvm_tests": ${LLVM_TESTS:-0},
            "llvm_failed": ${LLVM_FAILED:-0},
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
          }
          EOF
          cat llvm-test-results.json

      - name: Upload LLVM test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: llvm-test-results
          path: llvm-test-results.json
          retention-days: 90

  # Single status check for branch protection
  ci-success:
    name: CI Success
    needs: [version-check, format, clippy, test, cross-platform]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Check all jobs passed
        run: |
          if [[ "${{ needs.version-check.result }}" != "success" ]] || \
             [[ "${{ needs.format.result }}" != "success" ]] || \
             [[ "${{ needs.clippy.result }}" != "success" ]] || \
             [[ "${{ needs.test.result }}" != "success" ]] || \
             [[ "${{ needs.cross-platform.result }}" != "success" ]]; then
            echo "One or more required jobs failed"
            exit 1
          fi
          echo "All required checks passed!"
